{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text Analysis on Great Expectations Novel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports- **Run First**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Bring in text file with our novel\n",
    "textfile = open('great_expectations.txt', 'r', encoding = \"utf8\")\n",
    "great_expect = textfile.read()\n",
    "\n",
    "#print(great_expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import ldamodel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### How to clean text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lowercase words for word cloud\n",
    "word_cloud_text = great_expect.lower()\n",
    "\n",
    "#Remove numbers and alphanumeric words we don't need for word cloud\n",
    "\n",
    "word_cloud_text = re.sub(\"[^a-zA-Z0-9]\", \" \", word_cloud_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tokenize the data to split it into words\n",
    "tokens = word_tokenize(word_cloud_text)\n",
    "\n",
    "#Remove stopwords\n",
    "tokens = (word for word in tokens if word not in stopwords.words(\"english\"))\n",
    "\n",
    "#Remove short words less than 3 letters in length\n",
    "tokens = (word for word in tokens if len(word) >= 3)\n",
    "\n",
    "#print(list(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning to split data into sentences\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov|edu|me)\"\n",
    "digits = \"([0-9])\"\n",
    "\n",
    "text = \" \" + great_expect + \"  \"\n",
    "text = text.replace(\"\\n\",\" \")\n",
    "text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "if \"...\" in text: text = text.replace(\"...\",\"<prd><prd><prd>\")\n",
    "if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "text = text.replace(\".\",\".<stop>\")\n",
    "text = text.replace(\"?\",\"?<stop>\")\n",
    "text = text.replace(\"!\",\"!<stop>\")\n",
    "text = text.replace(\"<prd>\",\".\")\n",
    "sentences = text.split(\"<stop>\")\n",
    "sentences = [s.strip() for s in sentences]\n",
    "sentences = pd.DataFrame(sentences)\n",
    "sentences.columns = ['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10038\n",
      "                                            sentence\n",
      "0  ﻿The Project Gutenberg eBook of Great Expectat...\n",
      "1  You may copy it, give it away or re-use it und...\n",
      "2                                     gutenberg.org.\n",
      "3  If you are not located in the United States, y...\n",
      "4  Title: Great Expectations  Author: Charles Dic...\n",
      "5                                       Chapter III.\n",
      "6                                        Chapter IV.\n",
      "7                            Chapter V.  Chapter VI.\n",
      "8                                       Chapter VII.\n",
      "9                                      Chapter VIII.\n"
     ]
    }
   ],
   "source": [
    "#Print out sentences variable\n",
    "print(len(sentences))\n",
    "print(sentences.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Illustration]     Chapter I.   My father’s fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So, I called myself Pip, and came to be called...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I give Pirrip as my father’s family name, on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As I never saw my father or my mother, and nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The shape of the letters on my father’s, gave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From the character and turn of the inscription...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>To five little stone lozenges, each about a fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ours was the marsh country, down by the river,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My first most vivid and broad impression of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>At such a time I found out for certain that th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  [Illustration]     Chapter I.   My father’s fa...\n",
       "1  So, I called myself Pip, and came to be called...\n",
       "2  I give Pirrip as my father’s family name, on t...\n",
       "3  As I never saw my father or my mother, and nev...\n",
       "4  The shape of the letters on my father’s, gave ...\n",
       "5  From the character and turn of the inscription...\n",
       "6  To five little stone lozenges, each about a fo...\n",
       "7  Ours was the marsh country, down by the river,...\n",
       "8  My first most vivid and broad impression of th...\n",
       "9  At such a time I found out for certain that th..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the first few rows of text that are irrelevant for analysis\n",
    "sentences.drop(sentences.index[:59], inplace=True)\n",
    "sentences = sentences.reset_index(drop=True)\n",
    "sentences.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
